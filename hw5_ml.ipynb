{
  "metadata" : {
    "config" : {
      "dependencies" : {
        
      },
      "exclusions" : [
      ],
      "repositories" : [
      ],
      "sparkConfig" : {
        "spark.master" : "local[1]"
      },
      "env" : {
        
      }
    },
    "language_info" : {
      "name" : "scala"
    }
  },
  "nbformat" : 4,
  "nbformat_minor" : 0,
  "cells" : [
    {
      "cell_type" : "markdown",
      "execution_count" : 0,
      "metadata" : {
        "language" : "text"
      },
      "language" : "text",
      "source" : [
        "# hw5\n",
        "\n",
        "\n",
        "**Задание 1**. Merge Sort Join и Hash Join\n",
        "\n",
        "**Merge Sort Join**\n",
        "\n",
        "Плюсы:\n",
        "\n",
        "* Более эффективен для больших наборов данных, которые не помещаются в оперативную память, так как он не зависит от размера памяти\n",
        "* Более эффективен если данные уже отсортированы\n",
        "* Всегда работает за O(n log n)\n",
        "* Требования к памяти исполнителей для выполнения Sort Merge Join значительно ниже, чем для Shuffle Hash и Broadcast Hash<br>\n",
        "\n",
        "Недостатки:\n",
        "\n",
        "* На маленьких наборах данных работает медленнее Hash Join\n",
        "* Нужна предварительная сортировка \n",
        "\n",
        "**Hash Join**\n",
        "\n",
        "Плюсы:\n",
        "\n",
        "* Быстрый для меньших наборов данных, которые помещаются в память\n",
        "\n",
        "Недостатки:\n",
        "\n",
        "* Ограничен размером доступной памяти\n",
        "* При работе с данными, которые не умещаются в память, производительность падает из-за IO операций \n",
        "\n",
        "\n"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 1,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1703428666196,
          "endTs" : 1703428666735
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "import org.apache.spark.sql.SparkSession\r\n",
        "import org.apache.spark.sql.functions._\r\n",
        "\r\n",
        "// Соберите WordCount приложение, запустите на датасете ppkm_sentiment\r\n",
        "\r\n",
        "val sparkk = SparkSession.builder()\r\n",
        "  .appName(\"WordCount\")\r\n",
        "  .getOrCreate()\r\n",
        "\r\n",
        "val df = sparkk.read.option(\"header\", \"true\").csv(\"datasets/ppkmSentiment/ppkm_dataset.csv\")\r\n",
        "\r\n",
        "val wordsDf = df.select(explode(split(col(\"comment\"), \"\\\\s+\")).as(\"word\"))\r\n",
        "  .groupByKey(_.getString(0))\r\n",
        "  .count()\r\n",
        "  .toDF(\"word\", \"count\")\r\n",
        "\r\n",
        "wordsDf.show()"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "text" : [
            "+----------------+-----+\n",
            "|            word|count|\n",
            "+----------------+-----+\n",
            "|            PPKM|  100|\n",
            "|          patuhi|    3|\n",
            "|        semangat|    4|\n",
            "|           KEDUA|    1|\n",
            "|   PENGOPTIMALAN|    1|\n",
            "|          hingga|   11|\n",
            "|           #PTKM|    4|\n",
            "|          Dahulu|    1|\n",
            "|          baik\"\"|    1|\n",
            "|        generasi|    1|\n",
            "|          tumbuh|    1|\n",
            "|          Mangga|    1|\n",
            "|         artinya|    1|\n",
            "|         tagihan|    1|\n",
            "|          Jumlah|    1|\n",
            "|        Tracking|    1|\n",
            "|         operasi|    1|\n",
            "|          #Sumut|    1|\n",
            "|         Kapolda|    1|\n",
            "|bulan.PEMERINTAH|    1|\n",
            "+----------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "output_type" : "stream"
        }
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 2,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1703429969941,
          "endTs" : 1703429970437
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "// Измените WordCount так, чтобы он удалял знаки препинания и приводил все слова к единому регистру\r\n",
        "\r\n",
        "val cleanedWordsDf = df.select(explode(split(lower(regexp_replace(col(\"comment\"), \"[^\\\\w\\\\s]\", \"\")), \"\\\\s+\")).as(\"word\"))\r\n",
        "  .groupByKey(_.getString(0))\r\n",
        "  .count()\r\n",
        "  .toDF(\"word\", \"count\")\r\n",
        "\r\n",
        "cleanedWordsDf.show()"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "text" : [
            "+------------------+-----+\n",
            "|              word|count|\n",
            "+------------------+-----+\n",
            "|          semangat|    8|\n",
            "|            patuhi|    9|\n",
            "|            hingga|   13|\n",
            "|          generasi|    2|\n",
            "|            tumbuh|    1|\n",
            "|           pranowo|    2|\n",
            "|           artinya|    1|\n",
            "|           tagihan|    1|\n",
            "|httpstco3jtlpo1pwo|    1|\n",
            "|           operasi|    3|\n",
            "|httpstcopah0sasp9w|    1|\n",
            "|         erwin3977|    1|\n",
            "|            absurd|    1|\n",
            "|            bangun|    1|\n",
            "|           pembuat|    1|\n",
            "|             kabar|    1|\n",
            "|              gini|    1|\n",
            "|             bidan|    2|\n",
            "|httpstcohamun5p96h|    1|\n",
            "|            pidana|    1|\n",
            "+------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "output_type" : "stream"
        }
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 3,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1703428583862,
          "endTs" : 1703428585137
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "// Измените выход WordCount так, чтобы сортировка была по количеству повторений, а список слов был во втором столбце, а не в первом\r\n",
        "\r\n",
        "val sortedWordsDf = cleanedWordsDf.orderBy(desc(\"count\"))\r\n",
        "  .select(\"count\", \"word\")\r\n",
        "\r\n",
        "sortedWordsDf.show()"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "text" : [
            "+-----+-------------+\n",
            "|count|         word|\n",
            "+-----+-------------+\n",
            "|  134|         ppkm|\n",
            "|  110|        mikro|\n",
            "|   87|          dan|\n",
            "|   77|           di|\n",
            "|   71|      covid19|\n",
            "|   65|   masyarakat|\n",
            "|   59|    ppkmmikro|\n",
            "|   59|           yg|\n",
            "|   44|     kegiatan|\n",
            "|   43|   pembatasan|\n",
            "|   42| perpanjangan|\n",
            "|   33|           rt|\n",
            "|   31|          ada|\n",
            "|   31|     berbasis|\n",
            "|   29|         yang|\n",
            "|   29|        covid|\n",
            "|   28|        maret|\n",
            "|   27|        untuk|\n",
            "|   25|  humas_jogja|\n",
            "|   25|jogjaistimewa|\n",
            "+-----+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "output_type" : "stream"
        }
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 4,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1703428845089,
          "endTs" : 1703428846796
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "// Измените выход WordCount, чтобы формат соответствовал TSV\r\n",
        "\r\n",
        "sortedWordsDf.write.option(\"sep\", \"\\t\").mode(\"overwrite\").csv(\"wordcount_output.tsv\")"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 5,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1703430654972,
          "endTs" : 1703430655811
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "// Добавьте в WordCount возможность через конфигурацию задать список стоп-слов, которые будут отфильтрованы во время работы приложения\r\n",
        "\r\n",
        "val stopWordsDf = spark.read.text(\"datasets/ppkmSentiment/stopwordv1.txt\")\r\n",
        "val stopWords = stopWordsDf.as[String].collect()\r\n",
        "val broadcastStopWords = spark.sparkContext.broadcast(stopWords)\r\n",
        "\r\n",
        "val filteredWordsDf = wordsDf\r\n",
        "  .filter(!col(\"word\").isin(broadcastStopWords.value: _*))\r\n",
        "filteredWordsDf.show()"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "text" : [
            "+----------------+-----+\n",
            "|            word|count|\n",
            "+----------------+-----+\n",
            "|            PPKM|  100|\n",
            "|          patuhi|    3|\n",
            "|        semangat|    4|\n",
            "|           KEDUA|    1|\n",
            "|   PENGOPTIMALAN|    1|\n",
            "|           #PTKM|    4|\n",
            "|          Dahulu|    1|\n",
            "|          baik\"\"|    1|\n",
            "|        generasi|    1|\n",
            "|          tumbuh|    1|\n",
            "|          Mangga|    1|\n",
            "|         artinya|    1|\n",
            "|         tagihan|    1|\n",
            "|          Jumlah|    1|\n",
            "|        Tracking|    1|\n",
            "|         operasi|    1|\n",
            "|          #Sumut|    1|\n",
            "|         Kapolda|    1|\n",
            "|bulan.PEMERINTAH|    1|\n",
            "|          absurd|    1|\n",
            "+----------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "output_type" : "stream"
        }
      ]
    }
  ]
}